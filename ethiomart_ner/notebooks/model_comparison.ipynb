{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Model Comparison & Selection\n",
    "\n",
    "Compare multiple transformer models for Amharic NER using the improved training workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to sys.path\n",
    "SRC_PATH = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "from model_training.fixed_ner_trainer import FixedNERTrainer\n",
    "from model_training.ner_trainer import FinalNERPredictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to compare\n",
    "MODEL_CONFIGS = [\n",
    "    {\n",
    "        'name': 'xlm-roberta-base',\n",
    "        'output_dir': '../models/xlm_roberta_ner'\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-cased',\n",
    "        'output_dir': '../models/mb-bert_ner'\n",
    "    },\n",
    "    {\n",
    "        'name': 'distilbert-base-multilingual-cased',\n",
    "        'output_dir': '../models/distilbert_ner'\n",
    "    }\n",
    "]\n",
    "CONLL_FILE = '../data/labeled/conll_labeled.txt'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 3e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Each Model\n",
    "Run this cell for each model in MODEL_CONFIGS. (You can comment/uncomment as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model_training.fixed_ner_trainer:Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training xlm-roberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:model_training.fixed_ner_trainer:Loading and preparing data...\n",
      "INFO:model_training.fixed_ner_trainer:Loaded 50 sentences\n",
      "INFO:model_training.fixed_ner_trainer:Label distribution: {'I-PRICE': 17, 'O': 2047, 'B-PRODUCT': 14, 'B-LOC': 18, 'B-PRICE': 19}\n",
      "INFO:model_training.fixed_ner_trainer:Class weights: {0: 0.006839276990718124, 1: 0.7368421052631579, 2: 0.8235294117647058, 3: 0.7777777777777778, 4: 0.03309692671394799, 5: 1.0, 6: 0.03309692671394799}\n",
      "INFO:model_training.fixed_ner_trainer:Training set: 40 sentences\n",
      "INFO:model_training.fixed_ner_trainer:Validation set: 10 sentences\n",
      "Map: 100%|██████████| 40/40 [00:00<00:00, 2373.08 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 1429.11 examples/s]\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\src\\model_training\\fixed_ner_trainer.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "INFO:model_training.fixed_ner_trainer:Starting training with class balancing...\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 04:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Entity F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.123800</td>\n",
       "      <td>2.088685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.01744186046511628}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.143600</td>\n",
       "      <td>2.077349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.01744186046511628}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.152200</td>\n",
       "      <td>2.059990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.017543859649122806}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.106900</td>\n",
       "      <td>2.032979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.017595307917888565}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.067700</td>\n",
       "      <td>2.000849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.017804154302670624}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.997600</td>\n",
       "      <td>1.955901</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>{'PRICE': 0.0625, 'LOC': 0.012618296529968454}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.967900</td>\n",
       "      <td>1.890535</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>{'PRICE': 0.05660377358490566, 'LOC': 0.01646090534979424}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.859500</td>\n",
       "      <td>1.780377</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>{'PRICE': 0.02926829268292683, 'LOC': 0.041666666666666664}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.651700</td>\n",
       "      <td>1.563128</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.982806</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>{'PRICE': 0.024793388429752067, 'LOC': 0.05660377358490566}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.445400</td>\n",
       "      <td>1.402112</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>0.034923</td>\n",
       "      <td>0.982788</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>{'PRICE': 0.034482758620689655, 'LOC': 0.03550295857988166}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "INFO:model_training.fixed_ner_trainer:Saving model...\n",
      "INFO:model_training.fixed_ner_trainer:Training completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model xlm-roberta-base training complete!\n",
      "Training bert-base-multilingual-cased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model_training.fixed_ner_trainer:Loading tokenizer and model...\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Cyber Defense\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:model_training.fixed_ner_trainer:Loading and preparing data...\n",
      "INFO:model_training.fixed_ner_trainer:Loaded 50 sentences\n",
      "INFO:model_training.fixed_ner_trainer:Label distribution: {'I-PRICE': 17, 'O': 2047, 'B-PRODUCT': 14, 'B-LOC': 18, 'B-PRICE': 19}\n",
      "INFO:model_training.fixed_ner_trainer:Class weights: {0: 0.006839276990718124, 1: 0.7368421052631579, 2: 0.8235294117647058, 3: 0.7777777777777778, 4: 0.03309692671394799, 5: 1.0, 6: 0.03309692671394799}\n",
      "INFO:model_training.fixed_ner_trainer:Training set: 40 sentences\n",
      "INFO:model_training.fixed_ner_trainer:Validation set: 10 sentences\n",
      "Map: 100%|██████████| 40/40 [00:00<00:00, 2989.58 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 1881.19 examples/s]\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\src\\model_training\\fixed_ner_trainer.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "INFO:model_training.fixed_ner_trainer:Starting training with class balancing...\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 02:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Entity F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.906000</td>\n",
       "      <td>1.915063</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>0.979847</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.024242424242424242}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.856000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.073574</td>\n",
       "      <td>0.979981</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>{'PRICE': 0.02197802197802198, 'LOC': 0.03314917127071823}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.765300</td>\n",
       "      <td>1.707197</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>0.979965</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>{'PRICE': 0.023255813953488372, 'LOC': 0.030456852791878174}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.659000</td>\n",
       "      <td>1.579016</td>\n",
       "      <td>0.096203</td>\n",
       "      <td>0.154449</td>\n",
       "      <td>0.979997</td>\n",
       "      <td>0.096203</td>\n",
       "      <td>{'PRICE': 0.029850746268656716, 'LOC': 0.02727272727272727}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.454100</td>\n",
       "      <td>1.459041</td>\n",
       "      <td>0.129114</td>\n",
       "      <td>0.204831</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.129114</td>\n",
       "      <td>{'PRICE': 0.040268456375838924, 'LOC': 0.031914893617021274}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.253100</td>\n",
       "      <td>1.333943</td>\n",
       "      <td>0.149367</td>\n",
       "      <td>0.236814</td>\n",
       "      <td>0.980151</td>\n",
       "      <td>0.149367</td>\n",
       "      <td>{'PRICE': 0.0425531914893617, 'LOC': 0.03409090909090909}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.138000</td>\n",
       "      <td>1.216262</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>0.237176</td>\n",
       "      <td>0.980342</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>{'PRICE': 0.05517241379310345, 'LOC': 0.04477611940298507}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.924900</td>\n",
       "      <td>1.089182</td>\n",
       "      <td>0.169620</td>\n",
       "      <td>0.261197</td>\n",
       "      <td>0.980805</td>\n",
       "      <td>0.169620</td>\n",
       "      <td>{'PRICE': 0.06896551724137931, 'LOC': 0.09090909090909091}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.793300</td>\n",
       "      <td>0.953746</td>\n",
       "      <td>0.187342</td>\n",
       "      <td>0.288844</td>\n",
       "      <td>0.981770</td>\n",
       "      <td>0.187342</td>\n",
       "      <td>{'PRICE': 0.0684931506849315, 'LOC': 0.1016949152542373}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.717300</td>\n",
       "      <td>0.825834</td>\n",
       "      <td>0.263291</td>\n",
       "      <td>0.394987</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.263291</td>\n",
       "      <td>{'PRICE': 0.07042253521126761, 'LOC': 0.15}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "INFO:model_training.fixed_ner_trainer:Saving model...\n",
      "INFO:model_training.fixed_ner_trainer:Training completed!\n",
      "INFO:model_training.fixed_ner_trainer:Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bert-base-multilingual-cased training complete!\n",
      "Training distilbert-base-multilingual-cased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Cyber Defense\\.cache\\huggingface\\hub\\models--distilbert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:model_training.fixed_ner_trainer:Loading and preparing data...\n",
      "INFO:model_training.fixed_ner_trainer:Loaded 50 sentences\n",
      "INFO:model_training.fixed_ner_trainer:Label distribution: {'I-PRICE': 17, 'O': 2047, 'B-PRODUCT': 14, 'B-LOC': 18, 'B-PRICE': 19}\n",
      "INFO:model_training.fixed_ner_trainer:Class weights: {0: 0.006839276990718124, 1: 0.7368421052631579, 2: 0.8235294117647058, 3: 0.7777777777777778, 4: 0.03309692671394799, 5: 1.0, 6: 0.03309692671394799}\n",
      "INFO:model_training.fixed_ner_trainer:Training set: 40 sentences\n",
      "INFO:model_training.fixed_ner_trainer:Validation set: 10 sentences\n",
      "Map: 100%|██████████| 40/40 [00:00<00:00, 2651.22 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 903.05 examples/s]\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\src\\model_training\\fixed_ner_trainer.py:160: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "INFO:model_training.fixed_ner_trainer:Starting training with class balancing...\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 01:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Entity F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.930100</td>\n",
       "      <td>1.934124</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.068569</td>\n",
       "      <td>0.914598</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>{'PRICE': 0.0, 'LOC': 0.0392156862745098}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.895000</td>\n",
       "      <td>1.904593</td>\n",
       "      <td>0.048101</td>\n",
       "      <td>0.073310</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.048101</td>\n",
       "      <td>{'PRICE': 0.010526315789473684, 'LOC': 0.03550295857988166}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.840200</td>\n",
       "      <td>1.859699</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>0.082904</td>\n",
       "      <td>0.979976</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>{'PRICE': 0.02197802197802198, 'LOC': 0.03278688524590164}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.779600</td>\n",
       "      <td>1.798983</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>0.092175</td>\n",
       "      <td>0.979989</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>{'PRICE': 0.024691358024691357, 'LOC': 0.028708133971291867}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.690200</td>\n",
       "      <td>1.727935</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>0.087595</td>\n",
       "      <td>0.980006</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>{'PRICE': 0.025806451612903226, 'LOC': 0.02727272727272727}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.599100</td>\n",
       "      <td>1.639676</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>0.087810</td>\n",
       "      <td>0.980118</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>{'PRICE': 0.04054054054054054, 'LOC': 0.026200873362445413}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.495400</td>\n",
       "      <td>1.545685</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.092423</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>{'PRICE': 0.040268456375838924, 'LOC': 0.025974025974025976}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.355000</td>\n",
       "      <td>1.448427</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>0.980204</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>{'PRICE': 0.05263157894736842, 'LOC': 0.02702702702702703}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.222800</td>\n",
       "      <td>1.345497</td>\n",
       "      <td>0.073418</td>\n",
       "      <td>0.106322</td>\n",
       "      <td>0.980222</td>\n",
       "      <td>0.073418</td>\n",
       "      <td>{'PRICE': 0.05194805194805195, 'LOC': 0.028846153846153848}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.084900</td>\n",
       "      <td>1.231831</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.133302</td>\n",
       "      <td>0.980317</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>{'PRICE': 0.050955414012738856, 'LOC': 0.037037037037037035}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "INFO:model_training.fixed_ner_trainer:Saving model...\n",
      "INFO:model_training.fixed_ner_trainer:Training completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model distilbert-base-multilingual-cased training complete!\n"
     ]
    }
   ],
   "source": [
    "for config in MODEL_CONFIGS:\n",
    "    print(f\"Training {config['name']}...\")\n",
    "    trainer = FixedNERTrainer(config['name'])\n",
    "    trainer.train(\n",
    "        conll_file=CONLL_FILE,\n",
    "        output_dir=config['output_dir'],\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "    print(f\"Model {config['name']} training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation: Predict & Collect Metrics on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# Load and split data\n",
    "def load_conll_data(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    current_tokens = []\n",
    "    current_labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if current_tokens:\n",
    "                    sentences.append(current_tokens)\n",
    "                    labels.append(current_labels)\n",
    "                    current_tokens = []\n",
    "                    current_labels = []\n",
    "            else:\n",
    "                parts = line.split('\t')\n",
    "                if len(parts) == 2:\n",
    "                    token, label = parts\n",
    "                    current_tokens.append(token)\n",
    "                    current_labels.append(label)\n",
    "    if current_tokens:\n",
    "        sentences.append(current_tokens)\n",
    "        labels.append(current_labels)\n",
    "    return sentences, labels\n",
    "\n",
    "sentences, labels = load_conll_data(CONLL_FILE)\n",
    "train_sents, val_sents, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate all models and collect metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyber Defense\\Desktop\\week4\\ethiomart_ner\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlm-roberta-base - F1: 0.182, Accuracy: 0.876\n",
      "bert-base-multilingual-cased - F1: 0.101, Accuracy: 0.413\n",
      "distilbert-base-multilingual-cased - F1: 0.231, Accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "val_texts = [' '.join(tokens) for tokens in val_sents]\n",
    "for config in MODEL_CONFIGS:\n",
    "    predictor = FinalNERPredictor(config['output_dir'])\n",
    "    y_true = val_labels\n",
    "    y_pred = []\n",
    "    batch_results = predictor.batch_predict(val_texts, confidence_threshold=0.4)\n",
    "    for result, tokens in zip(batch_results, val_sents):\n",
    "        pred_labels = ['O'] * len(tokens)\n",
    "        for entity in result['entities']:\n",
    "            for idx in range(entity['start'], entity['end']+1):\n",
    "                if idx == entity['start']:\n",
    "                    pred_labels[idx] = f\"B-{entity['label']}\"\n",
    "                else:\n",
    "                    pred_labels[idx] = f\"I-{entity['label']}\"\n",
    "        y_pred.append(pred_labels)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    results.append({\n",
    "        'model': config['name'],\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'report': report\n",
    "    })\n",
    "    print(f\"{config['name']} - F1: {f1:.3f}, Accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Summary & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.876033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.413223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.913223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model        F1  Accuracy\n",
       "0                    xlm-roberta-base  0.181818  0.876033\n",
       "1        bert-base-multilingual-cased  0.101266  0.413223\n",
       "2  distilbert-base-multilingual-cased  0.230769  0.913223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a summary table\n",
    "summary = pd.DataFrame([{\n",
    "    'Model': r['model'],\n",
    "    'F1': r['f1'],\n",
    "    'Accuracy': r['accuracy']\n",
    "} for r in results])\n",
    "display(summary)\n",
    "\n",
    "# Plot F1 scores\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(summary['Model'], summary['F1'])\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Model Comparison: F1 Scores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Models Compared\n",
    "XLM-RoBERTa (xlm-roberta-base)\n",
    "mBERT (bert-base-multilingual-cased)\n",
    "DistilBERT (distilbert-base-multilingual-cased)\n",
    "Training\n",
    "All models were trained for 10 epochs on the same Amharic CoNLL-labeled dataset.\n",
    "Class balancing was used.\n",
    "Each model was saved to a unique output directory.\n",
    "Evaluation Metrics (on Validation Set)\n",
    "XLM-RoBERTa:\n",
    "F1 Score: 0.182\n",
    "Accuracy: 0.876\n",
    "mBERT:\n",
    "F1 Score: 0.101\n",
    "Accuracy: 0.413\n",
    "DistilBERT:\n",
    "F1 Score: 0.231\n",
    "Accuracy: 0.913\n",
    "Key Observations\n",
    "DistilBERT achieved the highest F1 (0.231) and accuracy (0.913), outperforming both XLM-RoBERTa and mBERT on this validation set.\n",
    "XLM-RoBERTa performed moderately well, with a decent accuracy but lower F1.\n",
    "mBERT had the lowest F1 and accuracy, indicating it struggled most with this dataset.\n",
    "There are warnings about some entity types not being predicted at all (likely due to data imbalance or small validation set).\n",
    "Conclusion\n",
    "DistilBERT is the best-performing model on your current validation set, followed by XLM-RoBERTa, with mBERT trailing.\n",
    "The notebook provides a clear, quantitative basis for model selection.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ethiomart venv)",
   "language": "python",
   "name": "ethiomart_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
