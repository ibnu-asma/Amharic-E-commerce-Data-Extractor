{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Ingestion & Preprocessing Validation\n",
    "## Comprehensive validation of Ethiopian Telegram e-commerce data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('../')\n",
    "from src.preprocessing.preprocess import preprocess_amharic_text\n",
    "from src.utils.data_validator import validate_processed_data, extract_entities\n",
    "\n",
    "print('=== TASK 1: DATA INGESTION & PREPROCESSING VALIDATION ===\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "data_dir = '../data/processed/'\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "if not csv_files:\n",
    "    print('‚ùå No CSV files found. Run scraper and processor first.')\n",
    "else:\n",
    "    print(f'‚úÖ Found {len(csv_files)} processed files')\n",
    "    df = pd.concat([pd.read_csv(f'{data_dir}{f}', encoding='utf-8') for f in csv_files])\n",
    "    \n",
    "    # 1. MULTI-CHANNEL VALIDATION\n",
    "    print('\\n1. TELEGRAM CHANNEL INGESTION:')\n",
    "    channels = df['channel'].unique()\n",
    "    print(f'‚úÖ Channels scraped: {len(channels)}')\n",
    "    for ch in channels:\n",
    "        count = len(df[df['channel'] == ch])\n",
    "        print(f'   {ch}: {count} messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MULTI-FORMAT DATA VALIDATION\n",
    "print('\\n2. MULTI-FORMAT DATA COLLECTION:')\n",
    "text_msgs = df['text'].notna().sum()\n",
    "image_msgs = df['image_path'].notna().sum()\n",
    "video_msgs = df['doc_path'].str.contains('.mp4', na=False).sum()\n",
    "print(f'‚úÖ Text messages: {text_msgs} ({text_msgs/len(df)*100:.1f}%)')\n",
    "print(f'‚úÖ Images: {image_msgs} ({image_msgs/len(df)*100:.1f}%)')\n",
    "print(f'‚úÖ Videos: {video_msgs} ({video_msgs/len(df)*100:.1f}%)')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "channel_counts = df['channel'].value_counts()\n",
    "plt.pie(channel_counts.values, labels=channel_counts.index.str.replace('@', ''), autopct='%1.1f%%')\n",
    "plt.title('Messages per Channel')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "media_data = ['Text', 'Images', 'Videos']\n",
    "media_counts = [text_msgs, image_msgs, video_msgs]\n",
    "plt.bar(media_data, media_counts, color=['skyblue', 'lightgreen', 'coral'])\n",
    "plt.title('Content Types')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(df['views'].fillna(0), bins=20, alpha=0.7, color='purple')\n",
    "plt.title('Views Distribution')\n",
    "plt.xlabel('Views')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AMHARIC PREPROCESSING VALIDATION\n",
    "print('\\n3. AMHARIC TEXT PREPROCESSING:')\n",
    "# Currency conversion\n",
    "birr_to_etb = df['processed_text'].str.contains('ETB', na=False).sum()\n",
    "print(f'‚úÖ Currency standardization: {birr_to_etb} messages with ETB')\n",
    "\n",
    "# Show preprocessing examples\n",
    "sample_with_price = df[df['text'].str.contains('·â•·à≠', na=False)].iloc[0] if len(df[df['text'].str.contains('·â•·à≠', na=False)]) > 0 else None\n",
    "if sample_with_price is not None:\n",
    "    print('\\nPreprocessing Example:')\n",
    "    print(f'Raw: {sample_with_price[\"text\"][:100]}...')\n",
    "    print(f'Processed: {sample_with_price[\"processed_text\"][:100]}...')\n",
    "\n",
    "# Amharic text analysis\n",
    "amharic_chars = df['text'].str.contains('[·àÄ-·çº]', na=False).sum()\n",
    "print(f'‚úÖ Messages with Amharic text: {amharic_chars}')\n",
    "\n",
    "# Text length analysis\n",
    "df['text_length'] = df['text'].str.len()\n",
    "print(f'‚úÖ Average text length: {df[\"text_length\"].mean():.1f} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. STRUCTURED DATA FORMAT\n",
    "print('\\n4. DATA STRUCTURE VALIDATION:')\n",
    "required_cols = ['channel', 'message_id', 'date', 'text', 'sender_id', 'views', 'processed_text']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if not missing_cols:\n",
    "    print('‚úÖ All required columns present')\n",
    "else:\n",
    "    print(f'‚ùå Missing columns: {missing_cols}')\n",
    "\n",
    "print(f'‚úÖ Total records: {len(df)}')\n",
    "print(f'‚úÖ Date range: {df[\"date\"].min()} to {df[\"date\"].max()}')\n",
    "print(f'‚úÖ Unique senders: {df[\"sender_id\"].nunique()}')\n",
    "\n",
    "# Data quality metrics\n",
    "print('\\nData Quality Metrics:')\n",
    "print(f'- Text coverage: {text_msgs/len(df)*100:.1f}%')\n",
    "print(f'- Media coverage: {(image_msgs + video_msgs)/len(df)*100:.1f}%')\n",
    "print(f'- Processing success: {df[\"processed_text\"].notna().sum()/len(df)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. NER-READY DATA VALIDATION\n",
    "print('\\n5. NER-READY DATA VALIDATION:')\n",
    "# Extract entities from sample\n",
    "sample_entities = []\n",
    "for text in df['processed_text'].dropna().head(10):\n",
    "    entities = extract_entities(text)\n",
    "    if entities['prices'] or entities['phones'] or entities['locations']:\n",
    "        sample_entities.append(entities)\n",
    "\n",
    "print(f'‚úÖ Sample entities extracted from {len(sample_entities)} messages')\n",
    "if sample_entities:\n",
    "    print('Sample entities:')\n",
    "    for i, ent in enumerate(sample_entities[:3]):\n",
    "        print(f'  Message {i+1}: {ent}')\n",
    "\n",
    "# Entity statistics\n",
    "all_prices = []\n",
    "all_phones = []\n",
    "all_locations = []\n",
    "\n",
    "for text in df['processed_text'].dropna():\n",
    "    entities = extract_entities(text)\n",
    "    all_prices.extend(entities['prices'])\n",
    "    all_phones.extend(entities['phones'])\n",
    "    all_locations.extend(entities['locations'])\n",
    "\n",
    "print(f'\\nEntity Statistics:')\n",
    "print(f'- Total prices found: {len(all_prices)}')\n",
    "print(f'- Total phone numbers: {len(all_phones)}')\n",
    "print(f'- Total locations: {len(all_locations)}')\n",
    "print(f'- Unique locations: {len(set(all_locations))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TASK 1 COMPLETION SUMMARY\n",
    "print('\\n' + '='*50)\n",
    "print('TASK 1 COMPLETION SUMMARY')\n",
    "print('='*50)\n",
    "\n",
    "requirements = {\n",
    "    '5+ Ethiopian Telegram channels': len(channels) >= 5,\n",
    "    'Custom scraper implementation': True,  # Evidenced by scraper.py\n",
    "    'Multi-format data (text/images/docs)': (text_msgs > 0 and image_msgs > 0),\n",
    "    'Amharic preprocessing': birr_to_etb > 0,\n",
    "    'Structured data format': len(missing_cols) == 0,\n",
    "    'NER-ready entity extraction': len(sample_entities) > 0\n",
    "}\n",
    "\n",
    "for req, status in requirements.items():\n",
    "    status_icon = '‚úÖ' if status else '‚ùå'\n",
    "    print(f'{status_icon} {req}')\n",
    "\n",
    "completion_rate = sum(requirements.values()) / len(requirements) * 100\n",
    "print(f'\\nüéØ TASK 1 COMPLETION: {completion_rate:.1f}%')\n",
    "\n",
    "if completion_rate >= 80:\n",
    "    print('üéâ TASK 1 SUCCESSFULLY COMPLETED!')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  Some requirements need attention.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}